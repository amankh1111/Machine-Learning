{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"California Housing Project with Functional API DNN\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, split and scale the California housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try1- Add inpuut layer to output layer as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           270         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           930         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 38)           0           input_2[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            39          concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2611 - val_loss: 3.3940\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6580 - val_loss: 0.9360\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5878 - val_loss: 0.5649\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5582 - val_loss: 0.5712\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5347 - val_loss: 0.5045\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5158 - val_loss: 0.4831\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5002 - val_loss: 0.4639\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4876 - val_loss: 0.4638\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4760 - val_loss: 0.4421\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4659 - val_loss: 0.4313\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4345\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.4498 - val_loss: 0.4168\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.4428 - val_loss: 0.4230\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 905us/step - loss: 0.4366 - val_loss: 0.4047\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 943us/step - loss: 0.4307 - val_loss: 0.4078\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.3938\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4210 - val_loss: 0.3952\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.4167 - val_loss: 0.3860\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 749us/step - loss: 0.4121 - val_loss: 0.3827\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 794us/step - loss: 0.4088 - val_loss: 0.4054\n",
      "162/162 [==============================] - 0s 588us/step - loss: 0.4032\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try2: Send 5 features (features 0 to 4), and 6 through the deep path (features 2 to 7). Note that 3 features will go through both (features 2, 3 and 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.8145 - val_loss: 0.8072\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6771 - val_loss: 0.6658\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.5687\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5584 - val_loss: 0.5296\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5334 - val_loss: 0.4993\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5120 - val_loss: 0.4811\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 0.4696\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4843 - val_loss: 0.4496\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4730 - val_loss: 0.4404\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4644 - val_loss: 0.4315\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.4570 - val_loss: 0.4268\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.4510 - val_loss: 0.4166\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4462 - val_loss: 0.4125\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4421 - val_loss: 0.4074\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4385 - val_loss: 0.4044\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4007\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4013\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.3987\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.3934\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.4261 - val_loss: 0.4204\n",
      "162/162 [==============================] - 0s 736us/step - loss: 0.4219\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test3 Adding an auxiliary output for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.1365 - main_output_loss: 1.9196 - aux_output_loss: 4.0890 - val_loss: 1.6233 - val_main_output_loss: 0.8468 - val_aux_output_loss: 8.6117\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8905 - main_output_loss: 0.6969 - aux_output_loss: 2.6326 - val_loss: 1.5163 - val_main_output_loss: 0.6836 - val_aux_output_loss: 9.0109\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7429 - main_output_loss: 0.6088 - aux_output_loss: 1.9499 - val_loss: 1.4639 - val_main_output_loss: 0.6229 - val_aux_output_loss: 9.0326\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6771 - main_output_loss: 0.5691 - aux_output_loss: 1.6485 - val_loss: 1.3388 - val_main_output_loss: 0.5481 - val_aux_output_loss: 8.4552\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6381 - main_output_loss: 0.5434 - aux_output_loss: 1.4911 - val_loss: 1.2177 - val_main_output_loss: 0.5194 - val_aux_output_loss: 7.5030\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6079 - main_output_loss: 0.5207 - aux_output_loss: 1.3923 - val_loss: 1.0935 - val_main_output_loss: 0.5106 - val_aux_output_loss: 6.3396\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5853 - main_output_loss: 0.5040 - aux_output_loss: 1.3175 - val_loss: 0.9918 - val_main_output_loss: 0.5115 - val_aux_output_loss: 5.3151\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5666 - main_output_loss: 0.4898 - aux_output_loss: 1.2572 - val_loss: 0.8733 - val_main_output_loss: 0.4733 - val_aux_output_loss: 4.4740\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5504 - main_output_loss: 0.4771 - aux_output_loss: 1.2101 - val_loss: 0.7832 - val_main_output_loss: 0.4555 - val_aux_output_loss: 3.7323\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5373 - main_output_loss: 0.4671 - aux_output_loss: 1.1695 - val_loss: 0.7170 - val_main_output_loss: 0.4604 - val_aux_output_loss: 3.0262\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5266 - main_output_loss: 0.4591 - aux_output_loss: 1.1344 - val_loss: 0.6510 - val_main_output_loss: 0.4293 - val_aux_output_loss: 2.6468\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5173 - main_output_loss: 0.4520 - aux_output_loss: 1.1048 - val_loss: 0.6051 - val_main_output_loss: 0.4310 - val_aux_output_loss: 2.1722\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5095 - main_output_loss: 0.4465 - aux_output_loss: 1.0765 - val_loss: 0.5644 - val_main_output_loss: 0.4161 - val_aux_output_loss: 1.8992\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5027 - main_output_loss: 0.4417 - aux_output_loss: 1.0511 - val_loss: 0.5354 - val_main_output_loss: 0.4119 - val_aux_output_loss: 1.6466\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4967 - main_output_loss: 0.4376 - aux_output_loss: 1.0280 - val_loss: 0.5124 - val_main_output_loss: 0.4047 - val_aux_output_loss: 1.4812\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4916 - main_output_loss: 0.4343 - aux_output_loss: 1.0070 - val_loss: 0.4934 - val_main_output_loss: 0.4034 - val_aux_output_loss: 1.3035\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4867 - main_output_loss: 0.4311 - aux_output_loss: 0.9872 - val_loss: 0.4801 - val_main_output_loss: 0.3984 - val_aux_output_loss: 1.2150\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4829 - main_output_loss: 0.4289 - aux_output_loss: 0.9686 - val_loss: 0.4694 - val_main_output_loss: 0.3962 - val_aux_output_loss: 1.1279\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4785 - main_output_loss: 0.4260 - aux_output_loss: 0.9510 - val_loss: 0.4580 - val_main_output_loss: 0.3936 - val_aux_output_loss: 1.0372\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4756 - main_output_loss: 0.4246 - aux_output_loss: 0.9344 - val_loss: 0.4655 - val_main_output_loss: 0.4048 - val_aux_output_loss: 1.0118\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 878us/step - loss: 0.4668 - main_output_loss: 0.4178 - aux_output_loss: 0.9082\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000028AB0442BF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing it using the The subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.5365 - output_1_loss: 2.3668 - output_2_loss: 4.0632 - val_loss: 1.3330 - val_output_1_loss: 1.1116 - val_output_2_loss: 3.3258\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9770 - output_1_loss: 0.8205 - output_2_loss: 2.3857 - val_loss: 0.9691 - val_output_1_loss: 0.7378 - val_output_2_loss: 3.0513\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7780 - output_1_loss: 0.6667 - output_2_loss: 1.7798 - val_loss: 0.8643 - val_output_1_loss: 0.6389 - val_output_2_loss: 2.8933\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6883 - output_1_loss: 0.5997 - output_2_loss: 1.4861 - val_loss: 0.7715 - val_output_1_loss: 0.5502 - val_output_2_loss: 2.7633\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6324 - output_1_loss: 0.5550 - output_2_loss: 1.3295 - val_loss: 0.7158 - val_output_1_loss: 0.5121 - val_output_2_loss: 2.5487\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5937 - output_1_loss: 0.5220 - output_2_loss: 1.2396 - val_loss: 0.6624 - val_output_1_loss: 0.4829 - val_output_2_loss: 2.2776\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5640 - output_1_loss: 0.4958 - output_2_loss: 1.1776 - val_loss: 0.6208 - val_output_1_loss: 0.4646 - val_output_2_loss: 2.0266\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5424 - output_1_loss: 0.4774 - output_2_loss: 1.1282 - val_loss: 0.5850 - val_output_1_loss: 0.4501 - val_output_2_loss: 1.7988\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5264 - output_1_loss: 0.4638 - output_2_loss: 1.0894 - val_loss: 0.5666 - val_output_1_loss: 0.4494 - val_output_2_loss: 1.6218\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5144 - output_1_loss: 0.4543 - output_2_loss: 1.0555 - val_loss: 0.5574 - val_output_1_loss: 0.4542 - val_output_2_loss: 1.4856\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5055 - output_1_loss: 0.4476 - output_2_loss: 1.0265 - val_loss: 0.5284 - val_output_1_loss: 0.4361 - val_output_2_loss: 1.3588\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4980 - output_1_loss: 0.4422 - output_2_loss: 0.9998 - val_loss: 0.5373 - val_output_1_loss: 0.4539 - val_output_2_loss: 1.2880\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4917 - output_1_loss: 0.4379 - output_2_loss: 0.9751 - val_loss: 0.5317 - val_output_1_loss: 0.4564 - val_output_2_loss: 1.2097\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.4861 - output_1_loss: 0.4343 - output_2_loss: 0.9529 - val_loss: 0.5038 - val_output_1_loss: 0.4349 - val_output_2_loss: 1.1242\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.4813 - output_1_loss: 0.4312 - output_2_loss: 0.9326 - val_loss: 0.5071 - val_output_1_loss: 0.4440 - val_output_2_loss: 1.0746\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.4771 - output_1_loss: 0.4285 - output_2_loss: 0.9146 - val_loss: 0.4891 - val_output_1_loss: 0.4306 - val_output_2_loss: 1.0154\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4733 - output_1_loss: 0.4262 - output_2_loss: 0.8971 - val_loss: 0.4917 - val_output_1_loss: 0.4377 - val_output_2_loss: 0.9778\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4695 - output_1_loss: 0.4238 - output_2_loss: 0.8805 - val_loss: 0.4869 - val_output_1_loss: 0.4363 - val_output_2_loss: 0.9415\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4659 - output_1_loss: 0.4215 - output_2_loss: 0.8654 - val_loss: 0.4729 - val_output_1_loss: 0.4248 - val_output_2_loss: 0.9050\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4631 - output_1_loss: 0.4200 - output_2_loss: 0.8510 - val_loss: 0.5081 - val_output_1_loss: 0.4656 - val_output_2_loss: 0.8906\n",
      "162/162 [==============================] - 0s 720us/step - loss: 0.4536 - output_1_loss: 0.4126 - output_2_loss: 0.8222\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), (y_valid, y_valid)))\n",
    "total_loss, main_loss, aux_loss = model.evaluate((X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 697us/step - loss: 0.4536 - output_1_loss: 0.4126 - output_2_loss: 0.8222\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    (X_test_A, X_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint Callback implementation during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 902us/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4474 - val_loss: 0.4379\n",
      "162/162 [==============================] - 0s 792us/step - loss: 0.4382\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # rollback to best model\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping Callback implementation during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.0148 - val_loss: 1.4007\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.7735 - val_loss: 1.3632\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6815 - val_loss: 0.8402\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.6134 - val_loss: 0.5897\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.5652 - val_loss: 0.5373\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 820us/step - loss: 0.5242 - val_loss: 0.5175\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.4955 - val_loss: 0.4717\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.4729 - val_loss: 0.4582\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.4546 - val_loss: 0.4201\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.4411 - val_loss: 0.4036\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.4311 - val_loss: 0.4122\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.4225 - val_loss: 0.3872\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.4156 - val_loss: 0.3814\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4095 - val_loss: 0.3763\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.4044 - val_loss: 0.3785\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.4005 - val_loss: 0.3682\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3969 - val_loss: 0.3984\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 800us/step - loss: 0.3943 - val_loss: 0.3625\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3907 - val_loss: 0.3610\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 767us/step - loss: 0.3882 - val_loss: 0.4561\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.3872 - val_loss: 0.3632\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.3841 - val_loss: 0.4075\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 717us/step - loss: 0.3823 - val_loss: 0.4608\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 842us/step - loss: 0.3804 - val_loss: 0.3983\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.3789 - val_loss: 0.3820\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.3772 - val_loss: 0.3785\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 685us/step - loss: 0.3760 - val_loss: 0.4521\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 890us/step - loss: 0.3746 - val_loss: 0.3948\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 758us/step - loss: 0.3735 - val_loss: 0.3700\n",
      "162/162 [==============================] - 0s 640us/step - loss: 0.3888\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_08_14-17_03_51'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8866 - val_loss: 0.7126\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 830us/step - loss: 0.6577 - val_loss: 0.6880\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 825us/step - loss: 0.5934 - val_loss: 0.5803\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.5557 - val_loss: 0.5166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 875us/step - loss: 0.5272 - val_loss: 0.4895\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 911us/step - loss: 0.5033 - val_loss: 0.4951\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.4854 - val_loss: 0.4861\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.4709 - val_loss: 0.4554\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 828us/step - loss: 0.4578 - val_loss: 0.4413\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 707us/step - loss: 0.4474 - val_loss: 0.4379\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.4393 - val_loss: 0.4396\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.4318 - val_loss: 0.4507\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.4261 - val_loss: 0.3997\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.4202 - val_loss: 0.3956\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 926us/step - loss: 0.4155 - val_loss: 0.3916\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.4112 - val_loss: 0.3937\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.4077 - val_loss: 0.3809\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 891us/step - loss: 0.4040 - val_loss: 0.3793\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 769us/step - loss: 0.4004 - val_loss: 0.3850\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 773us/step - loss: 0.3980 - val_loss: 0.3809\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 832us/step - loss: 0.3949 - val_loss: 0.3701\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3924 - val_loss: 0.3781\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 843us/step - loss: 0.3898 - val_loss: 0.3650\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.3874 - val_loss: 0.3655\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 891us/step - loss: 0.3851 - val_loss: 0.3611\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3829 - val_loss: 0.3626\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 763us/step - loss: 0.3809 - val_loss: 0.3564\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 642us/step - loss: 0.3788 - val_loss: 0.3579\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 755us/step - loss: 0.3769 - val_loss: 0.3561\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 799us/step - loss: 0.3750 - val_loss: 0.3548\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this code in Anaconda/Jupiter prompt\n",
    "tensorboard --logdir=./my_logs --port=6006 \n",
    "You can then open your web browser to [localhost:6006](http://localhost:6006) and use TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15276), started 0:36:49 ago. (Use '!kill 15276' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-55a2eaa20398e459\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-55a2eaa20398e459\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_08_14-17_07_17'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5530 - val_loss: 302.8466\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 827us/step - loss: 63.6669 - val_loss: 0.9735\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.9411 - val_loss: 0.9599\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 891us/step - loss: 0.9197 - val_loss: 0.8464\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.9819 - val_loss: 0.9281\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9240 - val_loss: 0.9089\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.9179 - val_loss: 0.8815\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.8950 - val_loss: 0.9007\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 955us/step - loss: 0.9150 - val_loss: 0.8734\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 852us/step - loss: 0.8921 - val_loss: 0.8507\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.9377 - val_loss: 0.8663\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 943us/step - loss: 0.8821 - val_loss: 0.8661\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8820 - val_loss: 0.8442\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 839us/step - loss: 0.8723 - val_loss: 0.8376\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 946us/step - loss: 2.0060 - val_loss: 0.8278\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 782us/step - loss: 1.0323 - val_loss: 0.8264\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 837us/step - loss: 0.8477 - val_loss: 0.8303\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.8441 - val_loss: 0.8028\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.8270 - val_loss: 0.8049\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 764us/step - loss: 0.8190 - val_loss: 0.7881\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 774us/step - loss: 0.8061 - val_loss: 0.8479\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.7955 - val_loss: 0.7850\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.7825 - val_loss: 0.7543\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.7755 - val_loss: 0.7205\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.7554 - val_loss: 0.8237\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 918us/step - loss: 0.8110 - val_loss: 0.7646\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.7860 - val_loss: 0.7630\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 910us/step - loss: 0.7753 - val_loss: 0.7558\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 696us/step - loss: 0.7526 - val_loss: 2.6873\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 806us/step - loss: 0.7860 - val_loss: 0.7643\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how TensorBoard now sees two runs, and you can compare the learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the other available logging options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, write_steps_per_second=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.0896 - val_loss: 20.7721\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7606 - val_loss: 5.0266\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5456 - val_loss: 0.5490\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4732 - val_loss: 0.4529\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4503 - val_loss: 0.4188\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4338 - val_loss: 0.4129\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4241 - val_loss: 0.4004\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4168 - val_loss: 0.3944\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4108 - val_loss: 0.3961\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4060 - val_loss: 0.4071\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.3855\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3984 - val_loss: 0.4136\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3951 - val_loss: 0.3997\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3921 - val_loss: 0.3818\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3894 - val_loss: 0.3829\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3869 - val_loss: 0.3739\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3848 - val_loss: 0.4022\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.3873\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3807 - val_loss: 0.3768\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.4191\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3774 - val_loss: 0.3927\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3756 - val_loss: 0.4237\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3742 - val_loss: 0.3523\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3725 - val_loss: 0.3842\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3710 - val_loss: 0.4162\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3700 - val_loss: 0.3980\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3691 - val_loss: 0.3473\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3677 - val_loss: 0.3921\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3670 - val_loss: 0.3566\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3653 - val_loss: 0.4191\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3647 - val_loss: 0.3722\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3633 - val_loss: 0.3948\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3632 - val_loss: 0.3423\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3617 - val_loss: 0.3454\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4068\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3608 - val_loss: 0.3417\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3596 - val_loss: 0.3787\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3589 - val_loss: 0.3379\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3419\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3572 - val_loss: 0.3705\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3570 - val_loss: 0.3660\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3563 - val_loss: 0.3803\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3552 - val_loss: 0.3766\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3814\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3543 - val_loss: 0.3326\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3532 - val_loss: 0.3385\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3527 - val_loss: 0.3657\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3521 - val_loss: 0.3576\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 0.3358\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3317\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3504 - val_loss: 0.3564\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3522\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3496 - val_loss: 0.4581\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3497 - val_loss: 0.3808\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3490 - val_loss: 0.3539\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3485 - val_loss: 0.3721\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.3336\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.4011\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.3263\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3271\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3452 - val_loss: 0.3348\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3453 - val_loss: 0.3492\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3444 - val_loss: 0.3401\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3450 - val_loss: 0.3274\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3437 - val_loss: 0.3296\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3431 - val_loss: 0.3307\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3428 - val_loss: 0.3252\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3242\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3419 - val_loss: 0.3254\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3413 - val_loss: 0.3659\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.3379\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3272\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3242\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3402 - val_loss: 0.3661\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3397 - val_loss: 0.3284\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3394 - val_loss: 0.3243\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3383 - val_loss: 0.3372\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3384 - val_loss: 0.3366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28aaf1399e8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 673us/step - loss: 0.3412\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8420 - val_loss: 0.4703\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4815 - val_loss: 0.4247\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4519 - val_loss: 0.4052\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4429 - val_loss: 0.3975\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4368 - val_loss: 0.3991\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4340 - val_loss: 0.4031\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 0.4043\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.3929\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4258 - val_loss: 0.4040\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4237 - val_loss: 0.3886\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 0.3999\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.4085\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4139 - val_loss: 0.3922\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.3918\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4106 - val_loss: 0.3886\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.3933\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.3907\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 0.3955\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4058 - val_loss: 0.3935\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.3891\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4251\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  10.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.7452 - val_loss: 0.4860\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.4280\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.5791\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4438 - val_loss: 0.4549\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4414 - val_loss: 0.5250\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.5486\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.5871\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4759\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.7523\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.7478\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4344 - val_loss: 0.8981\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.8543\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4537\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   6.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 10.8725 - val_loss: 4.2468\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0257 - val_loss: 0.5794\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5263 - val_loss: 0.4357\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4640 - val_loss: 0.4169\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.4135\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4486 - val_loss: 0.4206\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.4100\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4495 - val_loss: 0.4155\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4474 - val_loss: 0.4111\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4620 - val_loss: 0.4076\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.4062\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4078\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4462 - val_loss: 0.4160\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.4158\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4430 - val_loss: 0.4137\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4515 - val_loss: 0.4069\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4422 - val_loss: 0.4119\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4408 - val_loss: 0.4149\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4429 - val_loss: 0.4081\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.4141\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.4100\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4473\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  11.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.1684 - val_loss: 6.2480\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6285 - val_loss: 5.2166\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5212 - val_loss: 0.4474\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4280 - val_loss: 0.3901\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4008 - val_loss: 0.3736\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.3803\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.3813\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3648 - val_loss: 0.3961\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3591 - val_loss: 0.3988\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3542 - val_loss: 0.3891\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3510 - val_loss: 0.3870\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3465 - val_loss: 0.3769\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3424 - val_loss: 0.3770\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.3848\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3371 - val_loss: 0.3768\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3560\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=   8.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 0.8828 - val_loss: 3.5738\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4887 - val_loss: 0.7767\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4267 - val_loss: 0.5515\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4011 - val_loss: 0.5335\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3852 - val_loss: 0.5336\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.6750\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3678 - val_loss: 0.8462\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.8724\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.9645\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3525 - val_loss: 0.7225\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3475 - val_loss: 0.7257\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3442 - val_loss: 0.7216\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3422 - val_loss: 0.8440\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3407 - val_loss: 0.7065\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3650\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=   8.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 1.0015 - val_loss: 2.9433\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5546 - val_loss: 4.2557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4854 - val_loss: 2.8526\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4594 - val_loss: 1.6798\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4136 - val_loss: 0.4322\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3937 - val_loss: 0.4172\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.3769\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3753 - val_loss: 0.3688\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.4032\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.3418\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3610 - val_loss: 0.4452\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3575 - val_loss: 0.3454\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3526 - val_loss: 0.3395\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3503 - val_loss: 0.4354\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3489 - val_loss: 0.3386\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3455 - val_loss: 0.4038\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3302\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3406 - val_loss: 0.3580\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3386 - val_loss: 0.3548\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3360 - val_loss: 0.3459\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3355 - val_loss: 0.3246\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3338 - val_loss: 0.3259\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3315 - val_loss: 0.3443\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3301 - val_loss: 0.3379\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3289 - val_loss: 0.3639\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3271 - val_loss: 0.3903\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3256 - val_loss: 0.3139\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3237 - val_loss: 0.3205\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3261 - val_loss: 0.4282\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3235 - val_loss: 0.3220\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3197 - val_loss: 0.3135\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3177 - val_loss: 0.4312\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3183 - val_loss: 0.3112\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3151 - val_loss: 0.3930\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3179 - val_loss: 0.4466\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3143 - val_loss: 0.6042\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3157 - val_loss: 0.5986\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3197 - val_loss: 0.9304\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3169 - val_loss: 0.4521\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3120 - val_loss: 0.7242\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3137 - val_loss: 0.3448\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3081 - val_loss: 0.5422\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3101 - val_loss: 0.6252\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3169\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  24.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 4.3936 - val_loss: 13.3699\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2098 - val_loss: 10.8972\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.4360 - val_loss: 7.7330\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0926 - val_loss: 5.0744\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9168 - val_loss: 3.2363\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8186 - val_loss: 2.1597\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7619 - val_loss: 1.4840\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7266 - val_loss: 1.1083\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7031 - val_loss: 0.8942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6858 - val_loss: 0.7687\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6720 - val_loss: 0.6947\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6602 - val_loss: 0.6524\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6498 - val_loss: 0.6234\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6401 - val_loss: 0.6061\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6312 - val_loss: 0.5933\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6227 - val_loss: 0.5819\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6147 - val_loss: 0.5733\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6070 - val_loss: 0.5650\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5997 - val_loss: 0.5578\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5926 - val_loss: 0.5508\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5859 - val_loss: 0.5446\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5794 - val_loss: 0.5384\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5732 - val_loss: 0.5326\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5671 - val_loss: 0.5266\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5614 - val_loss: 0.5214\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5558 - val_loss: 0.5166\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5504 - val_loss: 0.5116\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.542 - 0s 2ms/step - loss: 0.5453 - val_loss: 0.5076\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5403 - val_loss: 0.5035\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5356 - val_loss: 0.4989\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5309 - val_loss: 0.4946\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5265 - val_loss: 0.4915\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5222 - val_loss: 0.4883\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5181 - val_loss: 0.4856\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5141 - val_loss: 0.4828\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5103 - val_loss: 0.4789\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 0.4780\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5030 - val_loss: 0.4742\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4995 - val_loss: 0.4729\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4962 - val_loss: 0.4714\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4929 - val_loss: 0.4686\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4897 - val_loss: 0.4666\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4867 - val_loss: 0.4646\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.4636\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4809 - val_loss: 0.4616\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.4582\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4755 - val_loss: 0.4581\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4729 - val_loss: 0.4573\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4704 - val_loss: 0.4560\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.4544\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4656 - val_loss: 0.4525\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4633 - val_loss: 0.4527\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4611 - val_loss: 0.4522\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4589 - val_loss: 0.4509\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.4509\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4548 - val_loss: 0.4513\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4529 - val_loss: 0.4496\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4510 - val_loss: 0.4510\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4502\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.4478\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4456 - val_loss: 0.4485\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4440 - val_loss: 0.4488\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4477\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4497\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4392 - val_loss: 0.4512\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.4484\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4483\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4349 - val_loss: 0.4494\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.4492\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4322 - val_loss: 0.4476\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4309 - val_loss: 0.4481\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4296 - val_loss: 0.4503\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4486\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.4491\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4496\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4483\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4474\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4490\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4217 - val_loss: 0.4495\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4206 - val_loss: 0.4468\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4492\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4186 - val_loss: 0.4525\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4504\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4525\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4158 - val_loss: 0.4495\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4148 - val_loss: 0.4548\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.4512\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.4481\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4472\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.4506\n",
      "121/121 [==============================] - 0s 650us/step - loss: 0.4209\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  37.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 1ms/step - loss: 3.4569 - val_loss: 7.5238\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5656 - val_loss: 8.6120\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0607 - val_loss: 8.4896\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8953 - val_loss: 7.7423\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8236 - val_loss: 6.8202\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7840 - val_loss: 5.9344\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7579 - val_loss: 5.1492\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7381 - val_loss: 4.4548\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7216 - val_loss: 3.9122\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7071 - val_loss: 3.4233\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6937 - val_loss: 2.9997\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6814 - val_loss: 2.6082\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6701 - val_loss: 2.2766\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6593 - val_loss: 1.9984\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6491 - val_loss: 1.7447\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6395 - val_loss: 1.5300\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6303 - val_loss: 1.3410\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6217 - val_loss: 1.1762\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6133 - val_loss: 1.0345\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6055 - val_loss: 0.9174\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5980 - val_loss: 0.8153\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5908 - val_loss: 0.7363\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5839 - val_loss: 0.6696\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5774 - val_loss: 0.6187\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5711 - val_loss: 0.5778\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5652 - val_loss: 0.5491\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5594 - val_loss: 0.5299\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5540 - val_loss: 0.5199\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5486 - val_loss: 0.5172\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5438 - val_loss: 0.5206\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5389 - val_loss: 0.5312\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5343 - val_loss: 0.5447\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5298 - val_loss: 0.5639\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 0.5821\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5216 - val_loss: 0.6039\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5177 - val_loss: 0.6306\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5140 - val_loss: 0.6564\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5104 - val_loss: 0.6820\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5069 - val_loss: 0.7087\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5160\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  19.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 3ms/step - loss: 4.0974 - val_loss: 7.4460\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1844 - val_loss: 5.2071\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4253 - val_loss: 2.9554\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0762 - val_loss: 1.7752\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9094 - val_loss: 1.1201\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8243 - val_loss: 0.8519\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7768 - val_loss: 0.7512\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7473 - val_loss: 0.7064\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7264 - val_loss: 0.6896\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.7098 - val_loss: 0.6760\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.6955 - val_loss: 0.6687\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 0.6830 - val_loss: 0.6577\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6713 - val_loss: 0.6454\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.6604 - val_loss: 0.6355\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.6503 - val_loss: 0.6256\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.6407 - val_loss: 0.6213\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.6317 - val_loss: 0.6120\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.6230 - val_loss: 0.6024\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6148 - val_loss: 0.5998\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6072 - val_loss: 0.5901\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5996 - val_loss: 0.5822\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5925 - val_loss: 0.5763\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5857 - val_loss: 0.5664\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.5791 - val_loss: 0.5574\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 0.5728 - val_loss: 0.5527\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.5668 - val_loss: 0.5452\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.5610 - val_loss: 0.5437\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 920us/step - loss: 0.5555 - val_loss: 0.5366\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.5501 - val_loss: 0.5322\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5450 - val_loss: 0.5264\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.5399 - val_loss: 0.5234\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 0.5352 - val_loss: 0.5175\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 984us/step - loss: 0.5305 - val_loss: 0.5137\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5262 - val_loss: 0.5078\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5219 - val_loss: 0.5045\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5178 - val_loss: 0.4970\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.5139 - val_loss: 0.4911\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.5101 - val_loss: 0.4887\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.5064 - val_loss: 0.4847\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.5029 - val_loss: 0.4815\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4994 - val_loss: 0.4776\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.4962 - val_loss: 0.4736\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4930 - val_loss: 0.4706\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4901 - val_loss: 0.4673\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4871 - val_loss: 0.4655\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4843 - val_loss: 0.4625\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4816 - val_loss: 0.4576\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.4789 - val_loss: 0.4554\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.4764 - val_loss: 0.4525\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.4740 - val_loss: 0.4495\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.4716 - val_loss: 0.4468\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.4693 - val_loss: 0.4446\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.4670 - val_loss: 0.4420\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.4649 - val_loss: 0.4394\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 0.4628 - val_loss: 0.4373\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 809us/step - loss: 0.4607 - val_loss: 0.4349\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 824us/step - loss: 0.4588 - val_loss: 0.4330\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 779us/step - loss: 0.4569 - val_loss: 0.4311\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.4550 - val_loss: 0.4291\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.4532 - val_loss: 0.4277\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.4515 - val_loss: 0.4257\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4498 - val_loss: 0.4241\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 0.4482 - val_loss: 0.4224\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 835us/step - loss: 0.4466 - val_loss: 0.4208\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 813us/step - loss: 0.4451 - val_loss: 0.4193\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.4436 - val_loss: 0.4180\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.4422 - val_loss: 0.4164\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.4408 - val_loss: 0.4151\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.4395 - val_loss: 0.4141\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4382 - val_loss: 0.4124\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4369 - val_loss: 0.4112\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4357 - val_loss: 0.4101\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4345 - val_loss: 0.4088\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.4334 - val_loss: 0.4081\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.4323 - val_loss: 0.4073\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.4312 - val_loss: 0.4070\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4301 - val_loss: 0.4056\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4291 - val_loss: 0.4040\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4281 - val_loss: 0.4034\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 980us/step - loss: 0.4271 - val_loss: 0.4033\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.4262 - val_loss: 0.4019\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.4253 - val_loss: 0.4008\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4002\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4236 - val_loss: 0.3996\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.3983\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.4219 - val_loss: 0.3980\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.4211 - val_loss: 0.3981\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.418 - 0s 966us/step - loss: 0.4203 - val_loss: 0.3969\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.4195 - val_loss: 0.3978\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4188 - val_loss: 0.3961\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.3951\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4173 - val_loss: 0.3938\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.4166 - val_loss: 0.3938\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.4159 - val_loss: 0.3935\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.4152 - val_loss: 0.3934\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 858us/step - loss: 0.4146 - val_loss: 0.3932\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 832us/step - loss: 0.4139 - val_loss: 0.3939\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 0.4132 - val_loss: 0.3913\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 0.4127 - val_loss: 0.3916\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.4121 - val_loss: 0.3918\n",
      "121/121 [==============================] - 0s 548us/step - loss: 0.4139\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  26.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 2.0765 - val_loss: 1.3536\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.7485 - val_loss: 0.7463\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6415 - val_loss: 0.5899\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5900 - val_loss: 0.5366\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.5507 - val_loss: 0.5063\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.4813\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4926 - val_loss: 0.4639\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4721 - val_loss: 0.4427\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4393\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.4137\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4071\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4224 - val_loss: 0.3983\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.3933\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4089 - val_loss: 0.3972\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4029 - val_loss: 0.3852\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3986 - val_loss: 0.3830\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.3947\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.3713\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3857 - val_loss: 0.3752\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3828 - val_loss: 0.3741\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3803 - val_loss: 0.3782\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3766 - val_loss: 0.3637\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3742 - val_loss: 0.3723\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 770us/step - loss: 0.3721 - val_loss: 0.3707\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 853us/step - loss: 0.3691 - val_loss: 0.4047\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3679 - val_loss: 0.3839\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3654 - val_loss: 0.4167\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.3500\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3792\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3602 - val_loss: 0.3636\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3476\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3566\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 0.3611\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.3414\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3527 - val_loss: 0.3474\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.3508 - val_loss: 0.3944\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3507 - val_loss: 0.4402\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.4723\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3496 - val_loss: 0.3722\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3481 - val_loss: 0.4019\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3376\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3449 - val_loss: 0.3377\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.3354\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3433 - val_loss: 0.3737\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3441 - val_loss: 0.3336\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3562\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3547\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3410 - val_loss: 0.3399\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.3400 - val_loss: 0.3304\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 0.3850\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3393 - val_loss: 0.3430\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3382 - val_loss: 0.3363\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3378 - val_loss: 0.3387\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3294\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3361 - val_loss: 0.3655\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3369 - val_loss: 0.3310\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3728\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3375\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3340 - val_loss: 0.3263\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3331 - val_loss: 0.3402\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.3329 - val_loss: 0.3440\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.3321 - val_loss: 0.3582\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 839us/step - loss: 0.3320 - val_loss: 0.3303\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3680\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.3311 - val_loss: 0.3293\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3311 - val_loss: 0.3276\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3299 - val_loss: 0.3563\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3297\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3282 - val_loss: 0.3445\n",
      "121/121 [==============================] - 0s 584us/step - loss: 0.3551\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  18.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8880 - val_loss: 3.40907\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7244 - val_loss: 1.6754\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6372 - val_loss: 0.9319\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5910 - val_loss: 0.6042\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5529 - val_loss: 0.5061\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5225 - val_loss: 0.5058\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.4977 - val_loss: 0.5272\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4770 - val_loss: 0.5600\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.4600 - val_loss: 0.5367\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.4469 - val_loss: 0.5220\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4356 - val_loss: 0.4878\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4531\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4182\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4124 - val_loss: 0.3877\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4064 - val_loss: 0.3818\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.4022\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4348\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.4934\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.5340\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.5982\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.6543\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.3786 - val_loss: 0.7246\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3758 - val_loss: 0.8046\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3735 - val_loss: 0.8587\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.3711 - val_loss: 0.9090\n",
      "121/121 [==============================] - 0s 693us/step - loss: 0.3884\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   7.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 1ms/step - loss: 2.1014 - val_loss: 2.1643\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7146 - val_loss: 0.6141\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.6063 - val_loss: 0.5601\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5633 - val_loss: 0.5241\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5017\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.5034 - val_loss: 0.4749\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4814 - val_loss: 0.4558\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4633 - val_loss: 0.4297\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4483 - val_loss: 0.4464\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4374 - val_loss: 0.4189\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.4266 - val_loss: 0.4438\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 0.4188 - val_loss: 0.4250\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4121 - val_loss: 0.4009\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4403\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.4025 - val_loss: 0.4014\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4247\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.3964\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 949us/step - loss: 0.3914 - val_loss: 0.3974\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.3887 - val_loss: 0.4229\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.4053\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.3840 - val_loss: 0.3989\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.3815 - val_loss: 0.3957\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.3864\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3774 - val_loss: 0.4022\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.3756 - val_loss: 0.3729\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.362 - 0s 983us/step - loss: 0.3733 - val_loss: 0.3645\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3716 - val_loss: 0.4107\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3702 - val_loss: 0.3925\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3688 - val_loss: 0.4265\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3677 - val_loss: 0.3879\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3789\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.4080\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3873\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3617 - val_loss: 0.4232\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3718\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3593 - val_loss: 0.3663\n",
      "121/121 [==============================] - 0s 632us/step - loss: 0.3555\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   9.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2908 - val_loss: 297.3652\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 825us/step - loss: 2.1716 - val_loss: 539.0366\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.2333 - val_loss: 3736.4512\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 812us/step - loss: 11.9933 - val_loss: 12227.6934\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 54.7040 - val_loss: 61529.0664\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 833us/step - loss: 2281.0823 - val_loss: 268363.5000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 2760.9941 - val_loss: 1210517.2500\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 40359.4062 - val_loss: 5411005.5000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 83691.9688 - val_loss: 24506692.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 612us/step - loss: 1055625.8750 - val_loss: 119813048.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 572us/step - loss: 1860448.3750 - val_loss: 529731200.0000\n",
      "121/121 [==============================] - 0s 360us/step - loss: 1402366.0000\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0446 - val_loss: 15.8284\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 732us/step - loss: 0.5210 - val_loss: 22.4892\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.5063 - val_loss: 24.7894\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 903us/step - loss: 0.5101 - val_loss: 22.4864\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.5097 - val_loss: 21.9009\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 673us/step - loss: 0.5089 - val_loss: 21.2895\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.5113 - val_loss: 19.9064\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 703us/step - loss: 0.5102 - val_loss: 22.5013\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.5069 - val_loss: 20.0987\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.5087 - val_loss: 10.7128\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 582us/step - loss: 0.5083 - val_loss: 19.7319\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 742us/step - loss: 0.5049 - val_loss: 24.3237\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 592us/step - loss: 0.5077 - val_loss: 25.9485\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.5199 - val_loss: 10.5277\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.5078 - val_loss: 17.1916\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.5064 - val_loss: 21.8346\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 745us/step - loss: 0.5058 - val_loss: 11.7743\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 752us/step - loss: 0.5101 - val_loss: 14.1555\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 880us/step - loss: 0.5071 - val_loss: 20.9814\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 866us/step - loss: 0.5032 - val_loss: 12.3621\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 25.9146\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5132 - val_loss: 16.0461\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5071 - val_loss: 19.4877\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 0.5084 - val_loss: 12.1054\n",
      "121/121 [==============================] - 0s 590us/step - loss: 0.7813\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   4.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 1ms/step - loss: 1.2328 - val_loss: 307.7495\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 0.9214 - val_loss: 76.3014\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 1.3774 - val_loss: 795.2289\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 34.9847 - val_loss: 704.0445\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 1.3027 - val_loss: 2668.0278\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 799us/step - loss: 9.2431 - val_loss: 1446.2603\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 4.8034 - val_loss: 1540.5377\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 41.9016 - val_loss: 1396.7119\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 10.9509 - val_loss: 1334.0858\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 885us/step - loss: 1.4803 - val_loss: 216.7274\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 787us/step - loss: 13.8366 - val_loss: 125.2067\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 816us/step - loss: 0.6450 - val_loss: 2.2902\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 830us/step - loss: 0.7449 - val_loss: 790.5425\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 790us/step - loss: 9.2398 - val_loss: 468.7425\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 859us/step - loss: 2.2300 - val_loss: 1073.9153\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 624us/step - loss: 37.3801 - val_loss: 865.6381\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 773us/step - loss: 8.9708 - val_loss: 1128.1495\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 3.8291 - val_loss: 499.5189\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 24.8681 - val_loss: 309.7941\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 3.6469 - val_loss: 354.6341\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 4.2841 - val_loss: 559.4487\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 4.5495 - val_loss: 393.8696\n",
      "121/121 [==============================] - 0s 502us/step - loss: 0.6226\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   4.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 1ms/step - loss: 1.2632 - val_loss: 1.4543\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 744us/step - loss: 0.6364 - val_loss: 0.9557\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 716us/step - loss: 0.5396 - val_loss: 0.4628\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 772us/step - loss: 0.4783 - val_loss: 0.4214\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4400 - val_loss: 0.3984\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 800us/step - loss: 0.4169 - val_loss: 0.4056\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3741\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3888 - val_loss: 0.3926\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.3832\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3743 - val_loss: 0.3929\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.3570\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3790\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3595 - val_loss: 0.3840\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3569 - val_loss: 0.3950\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3751\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3955\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3476 - val_loss: 0.3900\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3455 - val_loss: 0.3905\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.3420 - val_loss: 0.3944\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 786us/step - loss: 0.3404 - val_loss: 0.3811\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.3378 - val_loss: 0.3906\n",
      "121/121 [==============================] - 0s 640us/step - loss: 0.3624\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   5.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0130 - val_loss: 0.5822\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5558 - val_loss: 0.4873\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.4420\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4376 - val_loss: 0.4139\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4111 - val_loss: 0.4132\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3947 - val_loss: 0.4464\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4717\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.5331\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.6951\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.6944\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3574 - val_loss: 0.8506\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.7660\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3509 - val_loss: 0.8731\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3487 - val_loss: 0.9306\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3463 - val_loss: 0.9345\n",
      "121/121 [==============================] - 0s 627us/step - loss: 0.3685\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   4.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1090 - val_loss: 0.6796\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 0.4957\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4920 - val_loss: 0.4633\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4547 - val_loss: 0.4565\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.4150\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.4141 - val_loss: 0.4331\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 807us/step - loss: 0.4026 - val_loss: 0.3887\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3936 - val_loss: 0.3785\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.3857 - val_loss: 0.4233\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.3652\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.4336\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3725 - val_loss: 0.3763\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.3632\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.4460\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.3555\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3584 - val_loss: 0.3947\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3560 - val_loss: 0.3623\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.3774\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3505 - val_loss: 0.3807\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3420\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3463 - val_loss: 0.3452\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.3273\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3425 - val_loss: 0.3279\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 0.4346\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.3432\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3366 - val_loss: 0.3227\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.4466\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3322\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3982\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3323 - val_loss: 0.3431\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3294 - val_loss: 0.3346\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 0.3637\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 940us/step - loss: 0.3271 - val_loss: 0.3467\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.3243 - val_loss: 0.3582\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 875us/step - loss: 0.3245 - val_loss: 0.3141\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 982us/step - loss: 0.3223 - val_loss: 0.3636\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 865us/step - loss: 0.3220 - val_loss: 0.3376\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 922us/step - loss: 0.3212 - val_loss: 0.5255\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3313\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.4033\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.3345\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3650\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3162 - val_loss: 0.3311\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3684\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.3090\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3128 - val_loss: 0.3821\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.3187\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3118 - val_loss: 0.3007\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.3094 - val_loss: 0.4102\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3110 - val_loss: 0.3017\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3085 - val_loss: 0.4009\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3088 - val_loss: 0.3086\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3169\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3070 - val_loss: 0.3018\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3060 - val_loss: 0.3036\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 753us/step - loss: 0.3038 - val_loss: 0.3481\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3054 - val_loss: 0.3153\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.3048 - val_loss: 0.2978\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 728us/step - loss: 0.3034 - val_loss: 0.3107\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 746us/step - loss: 0.3038 - val_loss: 0.3228\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 774us/step - loss: 0.3022 - val_loss: 0.3199\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 758us/step - loss: 0.3012 - val_loss: 0.3000\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3156\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 846us/step - loss: 0.3008 - val_loss: 0.3358\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 0.3014 - val_loss: 0.3609\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.3007 - val_loss: 0.3171\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.2991 - val_loss: 0.2975\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.3154\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2976 - val_loss: 0.2953\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2961 - val_loss: 0.3082\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2964 - val_loss: 0.2886\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.2959 - val_loss: 0.2925\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2954 - val_loss: 0.2969\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.2854\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2946 - val_loss: 0.2990\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.3339\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2956 - val_loss: 0.2858\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.3068\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.2878\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2917 - val_loss: 0.2906\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.3037\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.2966\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2912 - val_loss: 0.2906\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2906 - val_loss: 0.3114\n",
      "121/121 [==============================] - 0s 636us/step - loss: 0.3054\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  23.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 1ms/step - loss: 2.1150 - val_loss: 29.5063\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 1.0854 - val_loss: 33.7785\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.9418 - val_loss: 4.0125\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.6369 - val_loss: 0.5556\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.5632 - val_loss: 0.5119\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.5371 - val_loss: 0.4888\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5149 - val_loss: 0.4729\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.4964 - val_loss: 0.4559\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 796us/step - loss: 0.4803 - val_loss: 0.4601\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.4670 - val_loss: 0.4303\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.4561 - val_loss: 0.4205\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.4469 - val_loss: 0.4242\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 0.4391 - val_loss: 0.4107\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.4325 - val_loss: 0.4231\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.4270 - val_loss: 0.4221\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.4221 - val_loss: 0.4084\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 945us/step - loss: 0.4179 - val_loss: 0.4209\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.4143 - val_loss: 0.4017\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4106 - val_loss: 0.4322\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.4080 - val_loss: 0.4001\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.4050 - val_loss: 0.4263\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.4027 - val_loss: 0.4032\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.4002 - val_loss: 0.4039\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.3981 - val_loss: 0.3764\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.3962 - val_loss: 0.4241\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 891us/step - loss: 0.3944 - val_loss: 0.3779\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.3925 - val_loss: 0.4126\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.3910 - val_loss: 0.3967\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.3889 - val_loss: 0.4045\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3880 - val_loss: 0.3748\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.3864 - val_loss: 0.3717\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3851 - val_loss: 0.3676\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.3837 - val_loss: 0.4054\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.3924\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3815 - val_loss: 0.3611\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.3800 - val_loss: 0.4182\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3792 - val_loss: 0.3539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3779 - val_loss: 0.4403\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3769 - val_loss: 0.3551\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 986us/step - loss: 0.3757 - val_loss: 0.4125\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.3748 - val_loss: 0.3665\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3735 - val_loss: 0.3591\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.3570\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.4125\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3714 - val_loss: 0.3547\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3699 - val_loss: 0.3779\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3692 - val_loss: 0.3886\n",
      "121/121 [==============================] - 0s 545us/step - loss: 0.3877\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  11.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8463 - val_loss: 0.7805\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7088 - val_loss: 1.1550\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6196 - val_loss: 1.8115\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5692 - val_loss: 2.6113\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5319 - val_loss: 3.2626\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.5046 - val_loss: 3.5247\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 974us/step - loss: 0.4841 - val_loss: 3.5926\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 928us/step - loss: 0.4679 - val_loss: 3.5562\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4551 - val_loss: 2.9541\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 2.5606\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4377 - val_loss: 2.1560\n",
      "121/121 [==============================] - 0s 683us/step - loss: 0.4866\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=   3.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 1ms/step - loss: 1.7445 - val_loss: 2.5834\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7268 - val_loss: 3.5564\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6419 - val_loss: 1.7895\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.6134 - val_loss: 1.7436\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 953us/step - loss: 0.5564 - val_loss: 0.6344\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.5303 - val_loss: 0.8713\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5070 - val_loss: 0.5604\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 0.4695\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.4759 - val_loss: 0.4942\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4659 - val_loss: 0.4375\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4561 - val_loss: 0.4536\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4481 - val_loss: 0.4276\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.4408 - val_loss: 0.4084\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.4354 - val_loss: 0.4897\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.4300 - val_loss: 0.4018\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.4246 - val_loss: 0.5505\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4602\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4171 - val_loss: 0.4347\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4132 - val_loss: 0.3835\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4092 - val_loss: 0.4115\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.3817\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4035 - val_loss: 0.3737\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4008 - val_loss: 0.3720\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3983 - val_loss: 0.4318\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 879us/step - loss: 0.3970 - val_loss: 0.4158\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.3943 - val_loss: 0.3821\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3922 - val_loss: 0.4069\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 870us/step - loss: 0.3909 - val_loss: 0.4024\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3887 - val_loss: 0.5904\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 0.4027\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3858 - val_loss: 0.4216\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.3847 - val_loss: 0.3603\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3825 - val_loss: 0.4134\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 957us/step - loss: 0.3819 - val_loss: 0.3633\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.3805 - val_loss: 0.3542\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3568\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.4216\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 0.3770 - val_loss: 0.5522\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.3792 - val_loss: 0.5648\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3763 - val_loss: 0.6416\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3785 - val_loss: 0.3847\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.5255\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.7023\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.7508\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3771 - val_loss: 0.5608\n",
      "121/121 [==============================] - 0s 747us/step - loss: 0.3745\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.0682 - val_loss: 6.4183\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7154 - val_loss: 16.7917\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5830 - val_loss: 4.7824\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4475 - val_loss: 8.6078\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4779 - val_loss: 1.8032\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3655\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3682 - val_loss: 0.3783\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3591 - val_loss: 0.4054\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3533 - val_loss: 0.3909\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3488 - val_loss: 0.3907\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3554\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3395 - val_loss: 0.3610\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3352 - val_loss: 0.3665\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3334 - val_loss: 0.3635\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3294 - val_loss: 0.3581\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.3566\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3580\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3224 - val_loss: 0.3482\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3540\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.3416\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3148 - val_loss: 0.3364\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3122 - val_loss: 0.3554\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3327\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3086\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.3491\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3032 - val_loss: 0.3064\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3027 - val_loss: 0.3316\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3428\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2984 - val_loss: 0.3363\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.2970\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.3073\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2934 - val_loss: 0.2944\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.3182\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2890 - val_loss: 0.3236\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.2904\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 0.3637\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.3502\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2857 - val_loss: 0.3625\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2839 - val_loss: 0.2941\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2820 - val_loss: 0.3314\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.2905\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 0.2891\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2785 - val_loss: 0.2901\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2766 - val_loss: 0.3148\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2766 - val_loss: 0.3174\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2756 - val_loss: 0.3225\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2736 - val_loss: 0.3003\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2734 - val_loss: 0.2856\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.2755\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2710 - val_loss: 0.3360\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2695 - val_loss: 0.3228\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2685 - val_loss: 0.3241\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2680 - val_loss: 0.2814\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2664 - val_loss: 0.2853\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2650 - val_loss: 0.2956\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2656 - val_loss: 0.2760\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2636 - val_loss: 0.3283\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2643 - val_loss: 0.2748\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.2886\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 976us/step - loss: 0.2610 - val_loss: 0.2774\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.2623 - val_loss: 0.3505\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 791us/step - loss: 0.2609 - val_loss: 0.2820\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 860us/step - loss: 0.2600 - val_loss: 0.3182\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.2597 - val_loss: 0.3008\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.2578 - val_loss: 0.2737\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 801us/step - loss: 0.2580 - val_loss: 0.2799\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 761us/step - loss: 0.2584 - val_loss: 0.3738\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2577 - val_loss: 0.2719\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2574 - val_loss: 0.3467\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2575 - val_loss: 0.2839\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2563 - val_loss: 0.4576\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2567 - val_loss: 0.2928\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.3401\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2534 - val_loss: 0.2755\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2530 - val_loss: 0.3753\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2526 - val_loss: 0.2755\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2539 - val_loss: 0.3902\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2535 - val_loss: 0.3194\n",
      "121/121 [==============================] - 0s 730us/step - loss: 0.3093\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  22.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8717 - val_loss: 0.7369\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5007 - val_loss: 0.4431\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 0.3919\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.3834\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.3951\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.4650\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3580 - val_loss: 0.6408\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.7273\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3462 - val_loss: 0.9105\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.6967\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.6960\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.3327 - val_loss: 0.7798\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3293 - val_loss: 0.8549\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3277 - val_loss: 0.8288\n",
      "121/121 [==============================] - 0s 505us/step - loss: 0.3525\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=   4.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 1ms/step - loss: 0.9177 - val_loss: 0.9196\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4767 - val_loss: 2.1025\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.4329 - val_loss: 3.5511\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 1.5867\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.3910 - val_loss: 0.4227\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3715 - val_loss: 0.3738\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3634 - val_loss: 0.3350\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3569 - val_loss: 0.3384\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3518 - val_loss: 0.3720\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3514 - val_loss: 0.3276\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3969\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3330\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3226\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3670\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.3323 - val_loss: 0.3203\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3294 - val_loss: 0.3560\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.3220\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3243 - val_loss: 0.3558\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3224 - val_loss: 0.3367\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3193 - val_loss: 0.3597\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3180 - val_loss: 0.3132\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3189\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3132 - val_loss: 0.3583\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3116 - val_loss: 0.3063\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3101 - val_loss: 0.3311\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3174\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3055 - val_loss: 0.3112\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3044 - val_loss: 0.3299\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3049 - val_loss: 0.3993\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3039 - val_loss: 0.3113\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.3272\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.3015\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2981 - val_loss: 0.3462\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2974 - val_loss: 0.2964\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2936 - val_loss: 0.2972\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2910 - val_loss: 0.3549\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.3539\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2930 - val_loss: 0.4022\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2915 - val_loss: 0.3154\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2909 - val_loss: 0.3909\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2873 - val_loss: 0.3042\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.3215\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2882 - val_loss: 0.2828\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.3319\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2842 - val_loss: 0.2950\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.3195\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2802 - val_loss: 0.2817\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2801 - val_loss: 0.2868\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2794 - val_loss: 0.3575\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2781 - val_loss: 0.2966\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2770 - val_loss: 0.3577\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2764 - val_loss: 0.2973\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2758 - val_loss: 0.3002\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2757 - val_loss: 0.3002\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2741 - val_loss: 0.2820\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2740 - val_loss: 0.3077\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2729 - val_loss: 0.3363\n",
      "121/121 [==============================] - 0s 711us/step - loss: 0.2931\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  17.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.9615 - val_loss: 10.9251\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5921 - val_loss: 3.3912\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4539 - val_loss: 0.4039\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3914 - val_loss: 0.3693\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3713 - val_loss: 0.3554\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3601 - val_loss: 0.3874\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3523 - val_loss: 0.3635\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3454 - val_loss: 0.3985\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3793\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3706\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3350 - val_loss: 0.3313\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3304 - val_loss: 0.3509\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3269 - val_loss: 0.3794\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3260 - val_loss: 0.3319\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3217 - val_loss: 0.3482\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3194 - val_loss: 0.3491\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3172 - val_loss: 0.3249\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3434\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3348\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3241\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3745\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3082 - val_loss: 0.3088\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.4155\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3080 - val_loss: 0.3835\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3038 - val_loss: 0.3595\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2992 - val_loss: 0.3133\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2983 - val_loss: 0.3367\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2973 - val_loss: 0.3549\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.3442\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2932 - val_loss: 0.3234\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2933 - val_loss: 0.3159\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2900 - val_loss: 0.3048\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2873 - val_loss: 0.3223\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2854 - val_loss: 0.3019\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2844 - val_loss: 0.2926\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2838 - val_loss: 0.3520\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2827 - val_loss: 0.2986\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.3689\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2812 - val_loss: 0.3030\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 0.3376\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2788 - val_loss: 0.2860\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2776 - val_loss: 0.3230\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3010\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2746 - val_loss: 0.3257\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2741 - val_loss: 0.2834\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2728 - val_loss: 0.3418\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2713 - val_loss: 0.3279\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.2819\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2690 - val_loss: 0.2761\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2693 - val_loss: 0.3422\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2682 - val_loss: 0.3317\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2661 - val_loss: 0.3510\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2684 - val_loss: 0.2790\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2651 - val_loss: 0.3185\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2635 - val_loss: 0.3131\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2639 - val_loss: 0.2954\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2623 - val_loss: 0.3419\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2630 - val_loss: 0.3006\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2620 - val_loss: 0.2866\n",
      "121/121 [==============================] - 0s 640us/step - loss: 0.3019\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  16.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8381 - val_loss: 0.6551\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4129\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.6097\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3911 - val_loss: 0.6574\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.6379\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.8601\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 1.0613\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3515 - val_loss: 1.1190\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 1.2255\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3424 - val_loss: 0.8015\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.8351\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3338 - val_loss: 0.7639\n",
      "121/121 [==============================] - 0s 791us/step - loss: 0.3595\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   4.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 0.8683 - val_loss: 2.2007\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5072 - val_loss: 3.3028\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4486 - val_loss: 0.9130\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 0.5328\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3609\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4151\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3659 - val_loss: 0.3580\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 0.3516\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3983\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3511 - val_loss: 0.3323\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.4228\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3283\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3463\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.4041\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3326 - val_loss: 0.3275\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3291 - val_loss: 0.3800\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3263 - val_loss: 0.3212\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.3228 - val_loss: 0.3300\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 848us/step - loss: 0.3216 - val_loss: 0.3821\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3190 - val_loss: 0.3409\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3179 - val_loss: 0.3752\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.3093\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3147 - val_loss: 0.3417\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3245\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3099 - val_loss: 0.3051\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3033\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3047 - val_loss: 0.4346\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3420\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3058 - val_loss: 0.3843\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3311\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.3117\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2978 - val_loss: 0.4216\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.3041\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2941 - val_loss: 0.3648\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.3054\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2923 - val_loss: 0.3757\n",
      "121/121 [==============================] - 0s 723us/step - loss: 0.3017\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  10.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2259 - val_loss: 0.5753\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5658 - val_loss: 8.9878\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5484 - val_loss: 11.0986\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5602 - val_loss: 1.1306\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4336 - val_loss: 0.5256\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4498\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.3939 - val_loss: 0.4056\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3835 - val_loss: 0.3999\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 808us/step - loss: 0.3766 - val_loss: 0.3957\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 907us/step - loss: 0.3712 - val_loss: 0.3904\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 0.3672 - val_loss: 0.3688\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3630 - val_loss: 0.3651\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.3709\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 0.3579 - val_loss: 0.3816\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 0.3534 - val_loss: 0.3620\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3670\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3490 - val_loss: 0.3671\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3474 - val_loss: 0.3605\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3445 - val_loss: 0.3552\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3538\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3417 - val_loss: 0.3520\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3388 - val_loss: 0.3477\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3372 - val_loss: 0.3509\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 0.3374 - val_loss: 0.3304\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.3333 - val_loss: 0.3683\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 0.3334 - val_loss: 0.3246\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.3336 - val_loss: 0.3389\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3322 - val_loss: 0.3366\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.3279 - val_loss: 0.3387\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3276 - val_loss: 0.3212\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 980us/step - loss: 0.3255 - val_loss: 0.3219\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.3256 - val_loss: 0.3151\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3239 - val_loss: 0.3458\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 819us/step - loss: 0.3221 - val_loss: 0.3163\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 847us/step - loss: 0.3209 - val_loss: 0.3140\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 817us/step - loss: 0.3191 - val_loss: 0.3896\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3189 - val_loss: 0.3819\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.3408\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3160 - val_loss: 0.3145\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.3154 - val_loss: 0.3381\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3158\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3149 - val_loss: 0.3136\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 941us/step - loss: 0.3148 - val_loss: 0.3110\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3112 - val_loss: 0.3381\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 897us/step - loss: 0.3145 - val_loss: 0.3052\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3103 - val_loss: 0.3269\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3089 - val_loss: 0.3292\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 978us/step - loss: 0.3120 - val_loss: 0.3221\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3075 - val_loss: 0.3022\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3069 - val_loss: 0.3504\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.3324\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 777us/step - loss: 0.3047 - val_loss: 0.3397\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3052 - val_loss: 0.3061\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3034 - val_loss: 0.3104\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3032 - val_loss: 0.3363\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 784us/step - loss: 0.3042 - val_loss: 0.2997\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.3759\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3035 - val_loss: 0.3257\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3001 - val_loss: 0.2981\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2991 - val_loss: 0.3213\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2997 - val_loss: 0.3224\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 797us/step - loss: 0.2982 - val_loss: 0.3493\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2985 - val_loss: 0.3085\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.3977\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2965 - val_loss: 0.2958\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3032 - val_loss: 0.3222\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.2951 - val_loss: 0.3343\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2942 - val_loss: 0.3023\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.2942 - val_loss: 0.3624\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 844us/step - loss: 0.2968 - val_loss: 0.2944\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2921 - val_loss: 0.3878\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 849us/step - loss: 0.2922 - val_loss: 0.3014\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2911 - val_loss: 0.2961\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 763us/step - loss: 0.2900 - val_loss: 0.3862\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.3031\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2891 - val_loss: 0.3306\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2927 - val_loss: 0.3871\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 713us/step - loss: 0.2904 - val_loss: 0.6477\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 918us/step - loss: 0.2952 - val_loss: 0.3554\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.2882 - val_loss: 0.4867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 655us/step - loss: 0.3230\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  21.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1975 - val_loss: 0.8898\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5319 - val_loss: 0.5270\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4524 - val_loss: 0.4844\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4250\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.3735\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3907 - val_loss: 0.3859\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.4576\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.4926\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 0.6246\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.5262\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.5952\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.6355\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.3550 - val_loss: 0.7437\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.3530 - val_loss: 0.7101\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.6821\n",
      "121/121 [==============================] - 0s 674us/step - loss: 0.3613\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=   4.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aman.khatri91425\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 2ms/step - loss: 1.1315 - val_loss: 2.8528\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6016 - val_loss: 2.3412\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.5108 - val_loss: 0.9015\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4594 - val_loss: 0.8313\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.5217\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4115 - val_loss: 0.4956\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 0.3745\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3917 - val_loss: 0.4012\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.384 - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4169\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.3843\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 0.3756 - val_loss: 0.6122\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 836us/step - loss: 0.3743 - val_loss: 0.3579\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 828us/step - loss: 0.3671 - val_loss: 0.3497\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 785us/step - loss: 0.3632 - val_loss: 0.5161\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 725us/step - loss: 0.3635 - val_loss: 0.4273\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 690us/step - loss: 0.3592 - val_loss: 0.5739\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 684us/step - loss: 0.3601 - val_loss: 0.4975\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 696us/step - loss: 0.3547 - val_loss: 0.4886\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 893us/step - loss: 0.3535 - val_loss: 0.3371\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.4118\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.3310\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3460 - val_loss: 0.3289\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.3435 - val_loss: 0.3287\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.5224\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 837us/step - loss: 0.3438 - val_loss: 0.7689\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.8909\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 767us/step - loss: 0.3448 - val_loss: 0.4864\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 822us/step - loss: 0.3369 - val_loss: 0.6169\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3373 - val_loss: 0.3470\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3327 - val_loss: 0.5750\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3332 - val_loss: 0.3685\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3308 - val_loss: 0.7292\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.335 - 0s 946us/step - loss: 0.3345 - val_loss: 0.3932\n",
      "121/121 [==============================] - 0s 530us/step - loss: 0.3362\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=   8.3s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8194 - val_loss: 1.8036\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.4857 - val_loss: 2.0827\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 804us/step - loss: 0.4266 - val_loss: 0.3796\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 813us/step - loss: 0.3857 - val_loss: 0.4283\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 897us/step - loss: 0.3740 - val_loss: 0.3617\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.3620 - val_loss: 0.4566\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 991us/step - loss: 0.3566 - val_loss: 0.3573\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3492 - val_loss: 0.3380\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.3432 - val_loss: 0.3757\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3389 - val_loss: 0.4069\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3380 - val_loss: 0.5455\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3368 - val_loss: 0.6470\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3109\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.3257 - val_loss: 0.3199\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3064\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 995us/step - loss: 0.3203 - val_loss: 0.3244\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3175 - val_loss: 0.3988\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.3153 - val_loss: 0.2991\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.3139 - val_loss: 0.3078\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 795us/step - loss: 0.3112 - val_loss: 0.4431\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 754us/step - loss: 0.3111 - val_loss: 0.3272\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.3076 - val_loss: 0.5079\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 737us/step - loss: 0.3067 - val_loss: 0.5685\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.3050 - val_loss: 0.5935\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 701us/step - loss: 0.3037 - val_loss: 0.2993\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 698us/step - loss: 0.2997 - val_loss: 0.6029\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 791us/step - loss: 0.3006 - val_loss: 0.5141\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 788us/step - loss: 0.3012 - val_loss: 0.4030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000028AB4E30978>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.007821074275112...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100).tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 74, 'n_hidden': 3, 'learning_rate': 0.005803602934201024}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31833014885584515"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x28ab1509eb8>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 546us/step - loss: 0.3029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.30288204550743103"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x28ab3c8e080>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 660us/step - loss: 0.3029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30288204550743103"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
